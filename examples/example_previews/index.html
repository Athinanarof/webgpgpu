<html>
<head></head>
<body>
<break/>
<h3>Basic examples</h3>
Basic examples that set up a two-dimensional rendering environment within the 3D WebGL framework, and then illustrate
basic rendering techniques like rendering from a texture, pixel operations like blurring, and random noise.
<break/>
<table>
<tr><td><a href="../Example_1_hello_gpu.html"><img src='example1.png' width='100px'/></a></td>
<td><a href="../Example_1_hello_gpu.html"><h4>Example 1: "Hello GPU"</h4></a><break/>
Set up an HTML Canvas for webGLM rendering, and render a simple coordinate-dependent image.
</td></tr>
<tr><td><a href="../Example_2_colormap_texture.html"><img src='example2.png' width='100px'/></a></td>
<td><a href="../Example_2_colormap_texture.html"><h4>Example 2: "1D texture"</h4></a><break/>
Use a one-dimensional texture as a colormap. 
Eventually, we will also render to texture to store rendering and simulation data between frames.
</td></tr>
<tr><td><a href="../Example_3_use_two_textures.html"><img src='example3.png' width='100px'/></a></td>
<td><a href="../Example_3_use_two_textures.html"><h4>Example 3: "Use two textures"</h4></a><break/>
Basic example loading two different colormaps as textures. 
Using multiple textures is important for rendering more complex systems, which may require more state than a single
red-green-blue texture can store.  
</td></tr>
<tr><td><a href="../Example_4_basic_blur.html"><img src='example4.png' width='100px'/></a></td>
<td><a href="../Example_4_basic_blur.html"><h4>Example 4: "Pixel blur"</h4></a><break/>
Vertical blur by averaging nearyby pixel values. This example demonstrate basic recursive/iterated computation on 
an image. 
</td></tr>
<tr><td><a href="../Example_5_gaussian_blur_separable.html"><img src='example5.png' width='100px'/></a></td>
<td><a href="../Example_5_gaussian_blur_separable.html"><h4>Example 5: "Separable Gaussian blur"</h4></a><break/>
We can compute larger Gaussian blurs quickly by blurring first horizontally and vertically. 
</td></tr>
<tr><td><a href="../Example_6_multi_blur.html"><img src='example6.png' width='100px'/></a></td>
<td><a href="../Example_6_multi_blur.html"><h4>Example 6: "Multi-color blur"</h4></a><break/>
For simulations, different colors might represent different quantities. This Gaussian blur kernel treats each
color channel separately, blurring them by different amounts.
</td></tr>
<tr><td><a href="../Example_7_pseudorandom_noise.html"><img src='example7.png' width='100px'/></a></td>
<td><a href="../Example_7_pseudorandom_noise.html"><h4>Example 7: "Noise"</h4></a><break/>
Stochastic simulations and animations require a source of noise. This kernel approximates uniform pseudorandom number
generation, in a fast ad-hoc way that is suitable for visualizations (not not guaranteed to be random enough for other
uses).
</td></tr>
<tr><td><a href="../Example_8_spatiotemporal_noise.html"><img src='example8.png' width='100px'/></a></td>
<td><a href="../Example_8_spatiotemporal_noise.html"><h4>Example 8: "Spatiotemporal noise"</h4></a><break/>
This example combines driving noise with repeated Gaussian blurs to create a spatiotemporal noise effect. 
</td></tr>
<tr><td><a href="../Example_11_bitops.html"><img src='example11.png' width='100px'/></a></td>
<td><a href="../Example_11_bitops.html"><h4>Example 11: "Bitops"</h4></a><break/>
WebGL doesn't explicitly support unsigned integer types and bit operations. However, most reasonable hardware and WebGL implementations should implicitly store color texture data as 8-bit integers. This kernel accesses this color data as if it were uint8, even though it is technically a float. 
</td></tr>
</table>


<break/>
<break/>
<h3>Image processing examples</h3>
These examples demonstrate basic image processing: color adjustments and blur/sharpen.
<break/>
<table>
<tr><td><a href="../Example_15_load_image.html"><img src='example15.png' width='100px'/></a></td>
<td><a href="../Example_15_load_image.html"><h4>Example 15: "Load image"</h4></a><break/>
This example loads an image resource, copies it to a texture, and displays it on screen.
</td></tr>
<tr><td><a href="../Example_16_hue_rotation.html"><img src='example16.png' width='100px'/></a></td>
<td><a href="../Example_16_hue_rotation.html"><h4>Example 16: "Linear hue rotation"</h4></a><break/>
This example demonstrates hue rotation as an optimize linear transformation using hue and chroma.
</td></tr>
<tr><td><a href="../Example_17_blur_image.html"><img src='example17.png' width='100px'/></a></td>
<td><a href="../Example_17_blur_image.html"><h4>Example 17: "Image blur"</h4></a><break/>
Apply iterated Guassian blur to image data.
</td></tr>
<tr><td><a href="../Example_17_unsharp_mask.html"><img src='example17b.png' width='100px'/></a></td>
<td><a href="../Example_17_unsharp_mask.html"><h4>Example 17b: "Unsharp mask"</h4></a><break/>
Apply iterated unsharp mask to image data.
</td></tr>
<tr><td><a href="../Example_19_contrast_and_brightness.html"><img src='example19.png' width='100px'/></a></td>
<td><a href="../Example_19_contrast_and_brightness.html"><h4>Example 19: "Brightness and contrast"</h4></a><break/>
Adjust brightness and contrast of image based on mouse location.
</td></tr>
<tr><td><a href="../Example_20_color_matrix_hue_and_saturation.html"><img src='example20.png' width='100px'/></a></td>
<td><a href="../Example_20_color_matrix_hue_and_saturation.html"><h4>Example 19: "Hue and saturation"</h4></a><break/>
Adjust hue and saturation of image based on mouse location.
</td></tr>
</table>


<break/>
<break/>
<h3>Technical experiments</h3>
These examples test a couple of technical tricks that might be useful in rendering. 
<break/>
<table>
<tr><td><a href="../Example_25_gaussian_noise.html"><img src='example25.png' width='100px'/></a></td>
<td><a href="../Example_25_gaussian_noise.html"><h4>Example 25: "Gaussian noise"</h4></a><break/>
Convert uniform random numbers to Gaussian random numbers with mean and variance specified by the mouse location. 
</td></tr>
<tr><td><a href="../Example_21_incremental_mipmaps.html"><img src='example21.png' width='100px'/></a></td>
<td><a href="../Example_21_incremental_mipmaps.html"><h4>Example 21: "Recursive mipmaps"</h4></a><break/>
Mipmaps are successively downsampled copies of a texture that are used to avoid aliasing. The are usually computed once, with a program is initialized. However, if we are rendering to texture data, and then want to use that data as a texture to color 3D objected, we may want to updates mipmaps. Rather than update all texture resolutions at once, however, we successively downsample on each iteration. meaning that lower-resolution mipmaps are updated later.
</td></tr>
<tr><td><a href="../Example_26_statistical_mipmap.html"><img src='example26.png' width='100px'/></a></td>
<td><a href="../Example_26_statistical_mipmap.html"><h4>Example 25: "Statistical mipmaps"</h4></a><break/>
Texture mipmaps compute the average texture color over a region, by downsampling. What if we'd like the average statistics, like mean and variance, over a given region? 
</td></tr><tr><td><a href="../Example_23_hello_particles.html"><img src='example23.png' width='100px'/></a></td>
<td><a href="../Example_23_hello_particles.html"><h4>Example 25: "Hello particles"</h4></a><break/>
Particle systems are useful in many-body simulations. This example uses texture data for particle location, and also renders each particle differently based on an offset into a texture.
</td></tr>
<tr><td><a href="../Example_13_mouse_tracking.html"><img src='example13.png' width='100px'/></a></td>
<td><a href="../Example_13_mouse_tracking.html"><h4>Example 13: "Julia set"</h4></a><break/>
Track the mouse location and render a Julia set using video feedback. 
</td></tr>
</table>


<break/>
<break/>
<h3>Psychedelic</h3>
These examples are "Just for fun"
<break/>
<table>
<tr><td><a href="../Example_9_quadratic_feedback.html"><img src='example9.png' width='100px'/></a></td>
<td><a href="../Example_9_quadratic_feedback.html"><h4>Example 9: "Quadratic feedback"</h4></a><break/>
Quadratic video feedback example of iterated conformal maps which can be used to render Julia set fractals. 
</td></tr>
<tr><td><a href="../Example_10_logarithmic_feedback.html"><img src='example10.png' width='100px'/></a></td>
<td><a href="../Example_10_logarithmic_feedback.html"><h4>Example 10: "Logarithmic feedback"</h4></a><break/>
Iterated logarithmic video feedback. The logarithmic map can be used to approximate the coordinate mapping from visual cortex to retinal (or "subjective") coordinates, which explains why some visual hallucinations take on a tunnel appearance. <i>(Ermentrout GB, Cowan JD. A mathematical theory of visual hallucination patterns. Biological cybernetics. 1979 Oct 1;34(3):137-50.)</i>
</td></tr>
<tr><td><a href="../Example_18_psychedelic_mask.html"><img src='example18b.png' width='100px'/></a></td>
<td><a href="../Example_18_psychedelic_mask.html"><h4>Example 18: "Psychedelic filter"</h4></a><break/>
Applies a combination of blues, sharpening, and hue rotations for a psychedelic image effect.
</td></tr>
<tr><td><a href="../Example_14_complex_arithmetic.html"><img src='example14b.png' width='100px'/></a></td>
<td><a href="../Example_14_complex_arithmetic.html"><h4>Example 14: "Complex arithmetic"</h4></a><break/>
Interpret length-2 vectors as complex numbers using a collection of macros. More sophisticated video feedback example. 
</td></tr>
<tr><td><a href="../Example_27_quasizoom.html"><img src='example27.png' width='100px'/></a></td>
<td><a href="../Example_27_quasizoom.html"><h4>Example 17: "Quasicrystal 1"</h4></a><break/>
An infinitely-zooming quasicrystal visualization with Shepard tone accompaniment, black and white.
</td></tr>
<tr><td><a href="../Example_28_quasizoom_color.html"><img src='example28.png' width='100px'/></a></td>
<td><a href="../Example_28_quasizoom_color.html"><h4>Example 17: "Quasicrystal 2"</h4></a><break/>
An infinitely-zooming quasicrystal visualization with Shepard tone accompaniment, color.
</td></tr>
</table>



<break/>
<break/>
<h3>Neural field simulations</h3>
Using only 8-bit color data to store state values means that these neural field simulations are only approximate. Some dynamical behaviors won't appear at parameters quite qhere the theory predicts. However, most qualitative behaviors are preserved.
<break/>
<table>
<tr><td><a href="../wilson_cowan_examples/WC_Example_1_basic.html"><img src='WCexample1.png' width='100px'/></a></td>
<td><a href="../wilson_cowan_examples/WC_Example_1_basic.html"><h4>Example 1: "Wilson-Cowan equations"</h4></a><break/>
Spiral wave emerge in a Wilson-Cowan neural field model. The lack of platform-specified rounding in WebGL means that these patteerns to not appear correcrtly on all devices (see example 2). 
</td></tr>
<tr><td><a href="../WC_Example_2_platform_independent_rounding.html"><img src='WCexample2.png' width='100px'/></a></td>
<td><a href="../wilson_cowan_examples/WC_Example_2_platform_independent_rounding.html"><h4>Example 2: "Platform independent rounding"</h4></a><break/>
Spiral wave emerge in a Wilson-Cowan neural field model. Additional macros enforce a platform-independent rounding rule, allowing for consistent behavior across devices.
</td></tr>
<tr><td><a href="../wilson_cowan_examples/WC_Example_3_wilson_cowan_center_surround.html"><img src='WCexample3.png' width='100px'/></a></td>
<td><a href="../wilson_cowan_examples/WC_Example_3_wilson_cowan_center_surround.html"><h4>Example 3: "Center-surround"</h4></a><break/>
Center surround "mexican hat" style coupling leads to the emergence of striped patterns in a Wilson-Cowan system.
</td></tr>
<tr><td><a href="../wilson_cowan_examples/WC_Example_4_periodic_forcing.html"><img src='WCexample4b.png' width='100px'/></a></td>
<td><a href="../wilson_cowan_examples/WC_Example_4_periodic_forcing.html"><h4>Example 4: "Flicker"</h4></a><break/>
Turing patterns induced in a Wilson-Cowan system by periodic forcing. 
<i>(Rule M, Stoffregen M, Ermentrout B. <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002158">A model for the origin and properties of flicker-induced geometric phosphenes.</a> PLoS computational biology. 2011 Sep 29;7(9):e1002158.)</i>
</td></tr>
<tr><td><a href="../wilson_cowan_examples/WC_Example_5_logarithmic_retinal_map.html"><img src='WCexample5.png' width='100px'/></a></td>
<td><a href="../wilson_cowan_examples/WC_Example_5_logarithmic_retinal_map.html"><h4>Example 5: "Retinotopic map"</h4></a><break/>
Use the logarithmic map to approximate how a Wilson-Cowan pattern forming system might appear in subjective coordinates, if the emergent waves were to occur in visual cortex. <i>(Ermentrout GB, Cowan JD. <a href="https://link.springer.com/article/10.1007/BF00336965">A mathematical theory of visual hallucination patterns.</a> Biological cybernetics. 1979 Oct 1;34(3):137-50.)</i>
</td></tr>
<tr><td><a href="../wilson_cowan_examples/WC_Example_9_wilson_cowan_fix_point_16_bit.html"><img src='WCexample9.png' width='100px'/></a></td>
<td><a href="../wilson_cowan_examples/WC_Example_9_wilson_cowan_fix_point_16_bit.html"><h4>Example 9: "16-bit precision"</h4></a><break/>
Use two color components, with 8-bits each, to implement 16-bit fixed-point storage of simulation states. This leads to a slightly more accurate numerical integration.
</td></tr>
<tr><td><a href="../wilson_cowan_examples/WC_Example_10_fullscreen.html"><img src='WCexample10.png' width='100px'/></a></td>
<td><a href="../wilson_cowan_examples/WC_Example_10_fullscreen.html"><h4>Example 10: "Fullscreen"</h4></a><break/>
Full-screen test of a logarithmically-mapped Wilson-Cowan pattern forming system.
</td></tr>
<tr><td><a href="../wilson_cowan_examples/WC_Example_11_acid_trip.html"><img src='WCexample11.png' width='100px'/></a></td>
<td><a href="../wilson_cowan_examples/WC_Example_11_acid_trip.html"><h4>Example 11: "Psychedelic"</h4></a><break/>
Full-screen test of a logarithmically-mapped Wilson-Cowan pattern forming system. Additional noise and hue rotation effects are added. This is purely a visual demonstration.
</td></tr>
</table>
</body>


